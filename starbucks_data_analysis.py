# -*- coding: utf-8 -*-
"""Starbucks_Data_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/arya8831/Starbucks-Data-Analysis/blob/main/Starbucks_Data_Analysis.ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd

import warnings
warnings.filterwarnings('ignore')

from google.colab import data_table
data_table.enable_dataframe_formatter()

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
import matplotlib.dates as mdates
import matplotlib.colors as mcolors
from matplotlib import style
import seaborn as sns
sns.set_style('whitegrid')
plt.style.use("fivethirtyeight")
# %matplotlib inline

# For reading stock data from yahoo
from pandas_datareader.data import DataReader

# For time stamps
from datetime import datetime
from math import sqrt

#ignore the warnings
import warnings
warnings.filterwarnings('ignore')


try:
    import mplfinance as mpf
    import mpl_finance as mplf
    from mpl_finance import candlestick_ohlc
except:
    !pip install mplfinance mpl_finance
    import mplfinance as mpf
    import mpl_finance as mplf
    from mpl_finance import candlestick_ohlc

import plotly.graph_objects as go

from google.colab import files
uploaded=files.upload()

"""**STARBUCKS STOCKS**"""

sbks_stock_action=pd.read_csv('Starbucks_stock_action.csv')
sbks_stock_action

sbks_stock_history=pd.read_csv('Starbucks_stock_history.csv')
sbks_stock_history

sbux = pd.read_csv('Starbucks_stock_history.csv')
sbux_info =  pd.read_csv('Starbucks_stock_info.csv',
                         header=None,
                         names=(['Description','Information']))
#sbux_info.dropna()
sbux_info.drop(sbux_info.loc[sbux_info['Information']=='nan'].index, inplace=True)
s = sbux_info.sort_values('Information').style
s

#Closing Price PLot
sbux[["Close"]].plot()
plt.xlabel('Volume')
plt.ylabel('Stock Price')

#Volume Plot
sbux[["Volume"]].plot()
plt.xlabel('Volume')

sbux2 = pd.read_csv('Starbucks_stock_history.csv', header=0,
                  index_col= 0, names=['Date','Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Splits'], parse_dates=True)
# Get the number of days in `sbux`
days = (sbux2.index[-1] - sbux2.index[0]).days

# Calculate the CAGR
cagr = ((((sbux2['Close'][-1]) / sbux2['Close'][1])) ** (365.0/days)) - 1


# Print CAGR
print("The CAGR (Compound Annual Growth Rate) of Starbucks since IPO is " , round((cagr*100),2), "% per year")

# Isolate the adjusted closing prices
adj_close_px = sbux2['Close']

# Calculate the moving average
moving_avg = adj_close_px.rolling(window=40).mean()

# Inspect the result
moving_avg[-10:]

# Short moving window rolling mean
sbux2['42'] = adj_close_px.rolling(window=40).mean()

# Long moving window rolling mean
sbux2['252'] = adj_close_px.rolling(window=252).mean()

# Plot the adjusted closing price, the short and long windows of rolling means
sbux2[['Close', '42', '252']].plot()

plt.show()

fig = go.Figure(data=go.Ohlc(x=sbux['Date'],
        open=sbux['Open'],
        high=sbux['High'],
        low=sbux['Low'],
        close=sbux['Close']))
fig.show()

daily_close_px = sbux2[['Close']]
# Calculate the daily percentage change for `daily_close_px`
daily_pct_change = daily_close_px.pct_change()

# Plot the distributions
daily_pct_change.hist(bins=50, sharex=True, figsize=(6,6))

# Show the resulting plot
plt.show()

# Define the minumum of periods to consider
min_periods = 75

# Calculate the volatility
vol = daily_pct_change.rolling(min_periods).std() * np.sqrt(min_periods)

# Plot the volatility
vol.plot(figsize=(8, 6))
plt.xlabel('Year')
plt.ylabel('Daily Percentage Change')

# Show the plot
plt.show()

sbux['SMA5'] = sbux.Close.rolling(5).mean()
sbux['SMA20'] = sbux.Close.rolling(20).mean()
sbux['SMA50'] = sbux.Close.rolling(50).mean()
sbux['SMA200'] = sbux.Close.rolling(200).mean()
sbux['SMA500'] = sbux.Close.rolling(500).mean()

fig = go.Figure(data=[go.Ohlc(x=sbux['Date'],
                              open=sbux['Open'],
                              high=sbux['High'],
                              low=sbux['Low'],
                              close=sbux['Close'], name = "OHLC"),
                      go.Scatter(x=sbux.Date, y=sbux.SMA5, line=dict(color='orange', width=1), name="SMA5"),
                      go.Scatter(x=sbux.Date, y=sbux.SMA20, line=dict(color='green', width=1), name="SMA20"),
                      go.Scatter(x=sbux.Date, y=sbux.SMA50, line=dict(color='blue', width=1), name="SMA50"),
                      go.Scatter(x=sbux.Date, y=sbux.SMA200, line=dict(color='violet', width=1), name="SMA200"),
                      go.Scatter(x=sbux.Date, y=sbux.SMA500, line=dict(color='purple', width=1), name="SMA500")])
fig.show()

sbux['EMA5'] = sbux.Close.ewm(span=5, adjust=False).mean()
sbux['EMA20'] = sbux.Close.ewm(span=20, adjust=False).mean()
sbux['EMA50'] = sbux.Close.ewm(span=50, adjust=False).mean()
sbux['EMA200'] = sbux.Close.ewm(span=200, adjust=False).mean()
sbux['EMA500'] = sbux.Close.ewm(span=500, adjust=False).mean()

fig = go.Figure(data=[go.Ohlc(x=sbux['Date'],
                              open=sbux['Open'],
                              high=sbux['High'],
                              low=sbux['Low'],
                              close=sbux['Close'], name = "OHLC"),
                      go.Scatter(x=sbux.Date, y=sbux.SMA5, line=dict(color='orange', width=1), name="EMA5"),
                      go.Scatter(x=sbux.Date, y=sbux.SMA20, line=dict(color='green', width=1), name="EMA20"),
                      go.Scatter(x=sbux.Date, y=sbux.SMA50, line=dict(color='blue', width=1), name="EMA50"),
                      go.Scatter(x=sbux.Date, y=sbux.SMA200, line=dict(color='violet', width=1), name="EMA200"),
                      go.Scatter(x=sbux.Date, y=sbux.SMA500, line=dict(color='purple', width=1), name="EMA500")])
fig.show()

sbux.set_index('Date')

sbux['daily_change_pct'] = sbux['Close'].pct_change()*100
sbux['returns'] = sbux['daily_change_pct'] / sbux['Close']
sbux.head()

sbux['daily_change_pct'].fillna(0)
sbux['daily_change_pct'].hist(bins = 50, figsize = (10,5))
plt.xlabel('Daily Change Percentage')
plt.ylabel('Frequency')
plt.show()
#print the statistics on daily change percentage
sbux.daily_change_pct.describe()

sbux_vol = sbux['Volume'].rolling(7).std()*np.sqrt(7)
sbux_vol.plot(figsize = (15, 7))
plt.xlabel('Volume')
plt.title('7-day rolling averages for volume of stocks traded')

def daily_trend(x):
    if x > -0.5 and x <= 0.5:
        return 'No change'
    elif x > 0.5 and x <= 2:
        return 'Upto 2% Increase'
    elif x > -2 and x <= -0.5:
        return 'Upto 2% Decrease'
    elif x > 2 and x <= 5:
        return '2-5% Increase'
    elif x > -5 and x <= -2:
        return '2-5% Decrease'
    elif x > 5 and x <= 10:
        return '5-10% Increase'
    elif x > -10 and x <= -5:
        return '5-10% Decrease'
    elif x > 10:
        return '>10% Increase'
    elif x <= -10:
        return '>10% Decrease'

sbux['Trend']= np.zeros(sbux['daily_change_pct'].count()+1)
sbux['Trend']= sbux['daily_change_pct'].apply(lambda x:daily_trend(x))
sbux['Trend'].replace('None','No change')
sbux.head()

sbux_pie_data = sbux.groupby('Trend')
pie_label = sbux_pie_data['Trend'].unique()
plt.pie(sbux_pie_data['Trend'].count(), #labels = pie_label,
        autopct = '%1.1f%%', radius = 2 )
plt.show()

ax=sbux_pie_data['Trend'].count().sort_values(ascending=False).plot.bar(rot=90)
plt.show()

sbux.index = pd.DatetimeIndex(sbux['Date'])
mpf.plot(sbux)

mpf.plot(sbux, type='candle', mav = (7, 30, 90, 180, 365), volume = True)

mpf.plot(sbux, type='candle', mav = (7, 30, 90, 180, 365), volume = True , show_nontrading = True)

sbux.head()

sbux['Shares'] = [1 if sbux.loc[ei, 'SMA20']>sbux.loc[ei, 'SMA50'] else 0 for ei in sbux.index]

sbux['Close1'] = sbux['Close'].shift(-1)
sbux['Profit'] = [sbux.loc[ei, 'Close1'] - sbux.loc[ei, 'Close'] if sbux.loc[ei, 'Shares']==1 else 0 for ei in sbux.index]
sbux['Profit'].plot()
plt.axhline(y=0, color='red')
plt.xlabel('Year')

sbux['wealth'] = sbux['Profit'].cumsum()
sbux.tail()

sbux['wealth'].plot()
plt.title('Total money made by Starbucks Stock (number of times ): {}'.format(round((sbux.loc[sbux.index[-2], 'wealth']),1)))
plt.xlabel('Year')
plt.ylabel('Price')

"""**STARBUCKS NUTRITION**"""

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.preprocessing import StandardScaler

from google.colab import files
uploaded=files.upload()

starbucks_full_menu = pd.read_csv('starbucks_drinkMenu_expanded.csv')
starbucks_drinks_menu = pd.read_csv('starbucks-menu-nutrition-drinks.csv')
starbucks_food_menu = pd.read_csv('starbucks-menu-nutrition-food.csv', encoding='utf-16')

starbucks_full_menu = starbucks_full_menu.rename(columns={' Total Fat (g)': 'Total Fat', 'Trans Fat (g) ': 'Trans Fat',
                                            'Saturated Fat (g)': 'Saturated Fat', ' Sodium (mg)': 'Sodium',
                                            ' Total Carbohydrates (g) ': 'Total Carbohydrates',
                                            'Cholesterol (mg)': 'Cholesterol', ' Dietary Fibre (g)': 'Dietary Fibre',
                                            ' Sugars (g)': 'Sugars', ' Protein (g) ': 'Protein',
                                            'Vitamin A (% DV) ': 'Vitamin A (% DV)', ' Calcium (% DV) ': 'Calcium (% DV)',
                                            'Iron (% DV) ': 'Iron (% DV)', 'Caffeine (mg)': 'Caffeine'})

starbucks_full_menu['Vitamin A (% DV)'] = "0." + starbucks_full_menu['Vitamin A (% DV)']
starbucks_full_menu['Vitamin C (% DV)'] = "0." + starbucks_full_menu['Vitamin C (% DV)']
starbucks_full_menu['Calcium (% DV)'] = "0." + starbucks_full_menu['Calcium (% DV)']
starbucks_full_menu['Iron (% DV)'] = "0." + starbucks_full_menu['Iron (% DV)']

starbucks_full_menu = starbucks_full_menu.replace({'Vitamin A (% DV)': {'%': ''}, 'Vitamin C (% DV)': {'%': ''},
                                     'Calcium (% DV)': {'%': ''}, 'Iron (% DV)': {'%': ''}}, regex=True)

starbucks_full_menu = starbucks_full_menu.replace({'Iron (% DV)': {'.00': ''}}, regex=True)

starbucks_full_menu.loc[237, 'Total Fat'] = '3.2'

starbucks_full_menu = starbucks_full_menu.replace({'Caffeine': {'Varies': None, 'varies': None}})

columns_to_change = ['Total Fat', 'Caffeine', 'Vitamin A (% DV)', 'Vitamin C (% DV)', 'Calcium (% DV)', 'Iron (% DV)']
starbucks_full_menu[columns_to_change] = starbucks_full_menu[columns_to_change].apply(pd.to_numeric)

starbucks_drinks_menu.replace('-', '', regex=True, inplace=True)
columns_to_change = ['Calories', 'Fat (g)', 'Carb. (g)', 'Fiber (g)', 'Protein', 'Sodium']
starbucks_drinks_menu[columns_to_change] = starbucks_drinks_menu[columns_to_change].apply(pd.to_numeric)

starbucks_drinks_menu.dropna(inplace=True)
starbucks_drinks_menu = starbucks_drinks_menu[~starbucks_drinks_menu.index.duplicated()]

iter_imputer = IterativeImputer(missing_values=np.nan, max_iter=10, verbose=0, imputation_order='roman', random_state=24)
starbucks_full_menu_num = starbucks_full_menu.iloc[:, 3:]
imp_full_menu_num = pd.DataFrame(iter_imputer.fit_transform(starbucks_full_menu_num))
starbucks_full_menu.iloc[:, 3:] = imp_full_menu_num

starbucks_drinks_menu = pd.read_csv('starbucks_drinkMenu_expanded.csv')
calories = starbucks_drinks_menu.sort_values('Calories', ascending=False)
calories

plt.figure(figsize=(10, 8))
sns.set_theme(style='whitegrid')
plot = sns.barplot(data=calories, x='Calories', y='Beverage', palette='crest')
plot.set(title='Highest Calorie Drinks', xlabel='Calories')
plt.xticks(rotation=0)
plt.show()

plt.figure(figsize=(7,4))
plot = sns.barplot(x=starbucks_drinks_menu['Calories'], y=starbucks_drinks_menu['Beverage_category']).set(xlabel='Category', ylabel='Average Calories', title='Average Calories per Beverage Category')
plt.xticks(rotation=0)
plt.show()

sns.set_theme(style='ticks')
sns.jointplot(data=calories, x='Calories', y='Cholesterol (mg)', kind='reg', color='#ff5555').fig.suptitle('Joint Distribution of Calories and Caffeine')
plt.show()

plt.figure(figsize=(15,7))
sns.set_theme(style='whitegrid')
sns.boxplot(data=starbucks_full_menu, x='Beverage_category', y='Caffeine', palette='hls').set(title='Distribution of Caffeine by Beverage Prep')
plt.xticks(rotation=45)
plt.show()

starbucks_food_menu = pd.read_csv('starbucks-menu-nutrition-food.csv', encoding='utf-16')
top20_cal = starbucks_food_menu.sort_values(' Calories', ascending=False).head(20)
top20_cal

plt.figure(figsize=(8, 6))
sns.set_theme(style='whitegrid')
plot = sns.barplot(data=top20_cal, y='Unnamed: 0', x=' Calories', palette='crest')
plot.set(title='Highest Calorie Foods', xlabel='Calories', ylabel='Food Items')
plt.xticks(rotation=0)
plt.show()

"""**CONSUMER DATA**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
# plt.style.use('fivethirtyeight')
# sns.set()

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn import metrics

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
# from sklearn.decomposition import PCA

from google.colab import files
uploaded=files.upload()

df_offer = pd.read_csv('portfolio.csv')
df_offer.head()

df_customer = pd.read_csv('profile.csv')
df_customer.head()

df_transcript = pd.read_csv('transcript.csv')
df_transcript.head()

df_offer = df_offer.drop('Unnamed: 0', axis = 1)
df_customer = df_customer.drop('Unnamed: 0', axis = 1)
df_transcript = df_transcript.drop('Unnamed: 0', axis = 1)

df_offer.isna().sum()

df_customer.isna().sum()

df_transcript.isna().sum()

missing_gender = df_customer[df_customer['gender'].isna()]
missing_income = df_customer[df_customer['income'].isna()]

np.sum(missing_gender['id'] == missing_income['id'])

id_to_remove = missing_income['id']
df_customer_no_na = df_customer[~df_customer['id'].isin(id_to_remove)]
df_customer_no_na = df_customer_no_na.reset_index(drop = True)
df_customer_no_na.info()

df_offer.info()

channels_0 = df_offer['channels'][0]
offer_type_0 = df_offer['offer_type'][0]
id_0 = df_offer['id'][0]

print('First value in column channels:', channels_0, '  --   Data type:', type(channels_0))
print('First value in column offer_type:', offer_type_0, '  --   Data type:', type(offer_type_0))
print('First value in column id:', id_0, '  --   Data type:', type(id_0))

df_customer_no_na.info()

df_customer_no_na['became_member_on'] = pd.to_datetime(df_customer_no_na['became_member_on'], format = '%Y%m%d')

df_transcript.info()

# Rename column `time`
df_transcript.rename(columns = {'time' : 'hours_since_start'}, inplace = True)
df_transcript.head(1)

# Check data type of column `value`
type(df_transcript['value'][0])

# Sort df offers
df_offer = df_offer.sort_values(['offer_type', 'difficulty']).reset_index(drop = True)

# Add column `offer_alias`
from string import ascii_uppercase
df_offer['offer_alias'] = [ascii_uppercase[i] for i in range(df_offer.shape[0])]
df_offer

# Elements in value_columns are strings. Convert them to dictionaries
value_column = df_transcript['value']
value_column = value_column.apply(eval)
value_column[:3]

# Extract the keys
dictionary_key_column = [list(d.keys())[0] for d in value_column]
# Extract the values
dictionary_value_column = [list(d.values())[0] for d in value_column]
# Create a df containing the keys and values of the dictionary elements of `value_column`
value_column_split = pd.DataFrame(columns = ['dict_key', 'dict_value'])
value_column_split['dict_key'] = dictionary_key_column
value_column_split['dict_value'] = dictionary_value_column
value_column_split.head(3)

# Replace `value` column with df `value_column_split`
df_transcript_value_mod = df_transcript.drop('value', axis = 1)
df_transcript_value_mod = pd.concat([df_transcript_value_mod, value_column_split], axis = 1)

# Reorder columns
df_transcript_value_mod.columns.values

col_names = ['person', 'event', 'dict_key', 'dict_value', 'hours_since_start']
df_transcript_value_mod = df_transcript_value_mod[col_names]
df_transcript_value_mod.sample(3)

offers = df_offer.copy()
customers = df_customer_no_na.copy()
transcripts = df_transcript_value_mod.copy()

wedge_size =  df_customer_no_na['gender'].value_counts()
wedge_label = ['Male', 'Female', 'Other']
plt.figure(figsize = (5,5))
plt.pie(x = wedge_size, labels = wedge_label, autopct = '%1.1f%%')
plt.title('Gender', fontsize = 16)
plt.show()

fig, axs = plt.subplots(1,2, figsize = (12,4))
sns.boxplot(data = customers, x = 'age', ax = axs[0])
sns.histplot(data = customers, x = 'age', ax = axs[1])
axs[0].xaxis.label.set_size(15)
axs[1].xaxis.label.set_size(15)
axs[1].yaxis.label.set_size(15)

print(customers['age'].describe())

# Create a new column `age_group`
age_group = pd.cut(customers['age'],
      bins = [customers['age'].min(), 26, 36, 46, 56, 66, 76, 86, customers['age'].max()],
      labels = ['18-25ys', '26-35ys', '36-45ys', '46-55ys', '56-65ys', '66-75ys', '76-85ys', '> 86ys'])
customers['age_group'] = age_group

# Visualize customers by age groups
age_group_percentage = (customers.value_counts('age_group').sort_index() / customers.shape[0] * 100).round(1)
plt.figure(figsize = (8, 5))
yticks = np.arange(0,25,5)
yticklabels = [str(y) + '%' for y in yticks]
plt.yticks(yticks, labels = yticklabels)
plt.xticks(rotation = 45, fontsize = 12)
plt.xlabel('Age', fontsize = 15)
plt.ylabel('Percentage %', fontsize = 15)
plt.title('Age Distribution', fontsize = 18)

bar_plot = plt.bar(x = age_group_percentage.index.values, height = age_group_percentage)
for i,bar in enumerate(bar_plot.patches):
    x, y = bar.get_xy()
    plt.text(x+bar.get_width()/2, y+bar.get_height()+0.2,
            str(age_group_percentage[i]) + '%',
            ha = 'center', weight = 'bold')

plt.tight_layout()
plt.show()

# Create a new column `income_group`
income_group = pd.cut(customers['income'],
      bins = [customers['income'].min(), 45000, 60000, 75000, 90000, 105000, customers['income'].max()],
      labels = ['30-45k', '45-60k', '60-75k', '75-90k', '90-105k', '> 105k'])
customers['income_group'] = income_group

# Visualize customers by income groups
income_group_percentage = (customers.value_counts('income_group').sort_index() / customers.shape[0] * 100).round(1)
plt.figure(figsize = (8, 5))
yticks = np.arange(0,30,5)
yticklabels = [str(y) + '%' for y in yticks]
plt.yticks(yticks, labels = yticklabels, fontsize = 12)
plt.xticks(fontsize = 12)
plt.xlabel('Income USD', fontsize = 15)
plt.ylabel('Percentage %', fontsize = 15)
plt.title('Income Distribution')

bar_plot = plt.bar(x = income_group_percentage.index.values, height = income_group_percentage)
for i,bar in enumerate(bar_plot.patches):
    x, y = bar.get_xy()
    plt.text(x+bar.get_width()/2, y+bar.get_height()+0.2,
            str(income_group_percentage[i]) + '%',
            ha = 'center', weight = 'bold', fontsize = 12)

plt.tight_layout()
plt.show()

print(customers.groupby('gender').agg({'age': 'mean'}))
sns.kdeplot(data = customers, x = 'age', hue = 'gender', fill = True)
plt.title('Age vs Gender', fontsize = 16)
plt.show()

print(customers.groupby('gender').agg({'income': 'mean'}))
sns.kdeplot(data = customers, x = 'income', hue = 'gender', fill = True)
plt.title('Income vs Gender', fontsize = 16)
plt.show()

sns.barplot(data = customers, x = 'age_group', y = 'income')
plt.xticks(rotation = 45)
ytick_labels = [str(i) + 'k' for i in (np.arange(0, 80000, 10000) / 1000).astype(int)]
plt.yticks(np.arange(0, 80000, 10000), labels = ytick_labels)
plt.title('Income vs Age', fontsize = 16)
plt.show()

p = offers.value_counts('channels')
plt.figure(figsize = (12,5))
sns.barplot(x = p.index.values, y = p.values)
plt.xticks(rotation = None, fontsize = 12)
plt.yticks(np.arange(5), fontsize = 14)
plt.xlabel('Channels', fontsize = 16, fontweight = 'bold')
plt.ylabel('Count', fontsize = 16, fontweight = 'bold')
plt.title('Promotion Channel', fontsize = 20)
plt.tight_layout()
plt.show()

# Create an empty df with columns needed
customer_behavior = pd.DataFrame(columns = ['person', 'num_received', 'num_viewed', 'num_completed', 'num_transactions', 'money_spent'])

# Remove rows of customers with missing gender and income
id_to_remove = missing_income['id']
transcripts_filtered = transcripts[~transcripts['person'].isin(id_to_remove)].reset_index(drop = True)

# Add data to `person`, ordered in ascending order
customer_behavior['person'] = transcripts_filtered.value_counts('person').sort_index().index.values

# Aggregate df transcripts
transcripts_filtered = transcripts_filtered.sort_values('person')
transcripts_grouped = transcripts_filtered.groupby(['person', 'event']).count()
transcripts_grouped.head()

# Set `person` as index for easy slicing
customer_behavior.set_index('person', inplace = True)

# Add data to `num_received`, `num_viewed`, `num_completed` and `num_transactions`
for person_id in customer_behavior.index.values:
    if (person_id, 'offer received') in list(transcripts_grouped.index.values):
        customer_behavior.loc[person_id, 'num_received'] = transcripts_grouped.loc[(person_id, 'offer received'), 'dict_key']
    if (person_id, 'offer viewed') in list(transcripts_grouped.index.values):
        customer_behavior.loc[person_id, 'num_viewed'] = transcripts_grouped.loc[(person_id, 'offer viewed'), 'dict_key']
    if (person_id, 'offer completed') in list(transcripts_grouped.index.values):
        customer_behavior.loc[person_id, 'num_completed'] = transcripts_grouped.loc[(person_id, 'offer completed'), 'dict_key']
    if (person_id, 'transaction') in list(transcripts_grouped.index.values):
        customer_behavior.loc[person_id, 'num_transactions'] = transcripts_grouped.loc[(person_id, 'transaction'), 'dict_key']

# Calculate how much money each customer spent during the month of the campaign
money_spent = transcripts_filtered[transcripts_filtered['event'] == 'transaction'].groupby('person').agg({'dict_value': 'sum'})

# Add to `money_spent`
customer_behavior['money_spent'] = money_spent
customer_behavior.head(3)

customer_behavior.isna().sum()

# Replace NA with 0
customer_behavior.fillna(0, inplace = True)
customer_behavior.isna().sum()

# Check the features with plots
fig, axs = plt.subplots(2,3, figsize = (14, 7))
fig_titles = ['Number of Offers Received', 'Number of Offers Viewed', 'Number of Offers Completed', 'Number of Transactions Made', 'Money Spent']
x_labels = ['Offers', 'Offers','Offers','Transactions','USD']
y_labels = 'Customer Count'

sub_row, sub_col = 0, 0

for i in range(5):
    if i < 3:
        sub_row = 0
        sub_col = i
        bins = customer_behavior.iloc[:, i].max()
        axs[sub_row, sub_col].hist(customer_behavior.iloc[:, i], bins = bins)
        axs[sub_row, sub_col].set_ylabel(y_labels, fontsize = 12)

    else:
        sub_row = 1
        sub_col = i - 3
        if i == 3:
            bins = customer_behavior.iloc[:, i].max()
            axs[sub_row, sub_col].hist(customer_behavior.iloc[:, i], bins = bins)
            axs[sub_row, sub_col].set_ylabel(y_labels, fontsize = 12)
        else:
            bins = 50
            axs[sub_row, sub_col].hist(customer_behavior.iloc[:, i], bins = bins)
            axs[sub_row, sub_col].set_ylabel(y_labels, fontsize = 12)

    axs[sub_row, sub_col].set_title(fig_titles[i], fontsize = 14)
    axs[sub_row, sub_col].set_xlabel(x_labels[i], fontsize = 12)

axs[1,2].set_axis_off()
plt.tight_layout()
plt.show()